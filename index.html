
<!DOCTYPE html>
<html lang="en" class="scroll-smooth" xmlns="http://www.w3.org/1999/xhtml" prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# website: http://ogp.me/ns/website#">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<title>IMO-Bench: Towards Robust Mathematical Reasoning | Google DeepMind</title>
<meta name="keywords" content="IMO-Bench, mathematical reasoning, proof writing, autograder, benchmark, AI reasoning, Deep Think, Gemini, EMNLP 2025" />
<meta name="description" content="IMO-Bench is a suite of benchmarks for robust mathematical reasoning, including AnswerBench, ProofBench, and GradingBench, introduced at EMNLP 2025 by Thang Luong et. al., Google DeepMind." />
<meta name="author" content="Thang Luong et. al., Google DeepMind" />
<meta name="googlebot" content="noarchive" />
<meta name="robots" content="noarchive" />
<meta name="theme-color" content="#2c3e50">
<meta name="ROBOTS" content="index, follow" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="shortcut icon" type="image/png" href="imgs/favicon.png"/>
<link rel="canonical" href="https://imobench.github.io/"/>
<meta property="og:title" content="IMO-Bench: Towards Robust Mathematical Reasoning | Google DeepMind">
<meta property="og:image" content="https://imobench.github.io/imgs/thumbnail-share.jpg">
<meta property="og:image:secure_url" content="https://imobench.github.io/imgs/thumbnail-share.jpg" />
<meta property="og:image:width" content="1200" />
<meta property="og:image:height" content="630" />
<meta property="og:image:alt" content="IMO-Bench: Towards Robust Mathematical Reasoning - correlation between human and automatic evaluations">
<meta property="og:site_name" content="IMO-Bench">
<meta property="og:description" content="IMO-Bench is a suite of benchmarks for robust mathematical reasoning, including AnswerBench, ProofBench, and GradingBench, introduced at EMNLP 2025 by Thang Luong et. al., Google DeepMind.">
<meta property="og:type" content="website">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://imobench.github.io/imgs/thumbnail-share.jpg">
<meta name="twitter:creator" content="Google DeepMind">
<meta name="twitter:title" content="IMO-Bench: Towards Robust Mathematical Reasoning | Google DeepMind">
<meta name="twitter:description" content="IMO-Bench is a suite of benchmarks for robust mathematical reasoning, including AnswerBench, ProofBench, and GradingBench, introduced at EMNLP 2025 by Thang Luong et. al., Google DeepMind.">
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<!-- Tailwind CSS -->
<script src="https://cdn.tailwindcss.com"></script>
<script>
    tailwind.config = {
        theme: {
            extend: {
                fontFamily: {
                    sans: ['-apple-system', 'BlinkMacSystemFont', 'Segoe UI', 'Helvetica', 'Arial', 'sans-serif'],
                    mono: ['SFMono-Regular', 'Consolas', 'Liberation Mono', 'Menlo', 'monospace'],
                },
            }
        }
    }
</script>
<!-- Load Phosphor Icons for the buttons -->
<script src="https://unpkg.com/@phosphor-icons/web@2.0.3/dist/assets/index.js"></script>
</head>
<body class="bg-gray-900/5 text-gray-900 antialiased py-4" >
<div class="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-8 lg:py-12 bg-white/95 rounded-2xl shadow-2xl ring-1 ring-black/5">
    <!-- Header Logo -->
    <div class="mb-6 flex items-start justify-between border-b border-gray-200">
         <!-- Main Title -->
    <div class="mb-4 pb-4 ">
        <img src="imgs/Google_DeepMind_Logo_rgb_3320x512px.png" 
        height="32" 
        class="h-8 sm:h-10 w-auto object-contain mb-6" >
        <h1 class="text-3xl md:text-4xl font-bold text-gray-900">Towards Robust Mathematical Reasoning</h1>
        
    </div>
        <img src="imgs/logo-imobench.png" class="h-24 sm:h-24 w-auto rounded object-contain">
    </div>
    <!-- AUTHORS -->
    <div class="text-base md:text-lg text-gray-800 mb-6 leading-relaxed">
        <p class="mb-2 text-base">
           
           Thang Luong<sup class="text-blue-600 font-semibold">◊</sup>(<em>lead</em>),
            Dawsen Hwang<sup class="text-blue-600 font-semibold">*</sup>,
            Hoang Nguyen<sup class="text-blue-600 font-semibold">*†</sup>
            Golnaz Ghiasi<sup class="text-blue-600 font-semibold">*</sup>,
            Yuri Chervonyi<sup class="text-blue-600 font-semibold">*</sup>,
            Insuk Seo<sup class="text-blue-600 font-semibold">*</sup>,
            Junsu Kim<sup class="text-blue-600 font-semibold">*</sup>
            Garrett Bingham,
            Jonathan Lee,
            Swaroop Mishra<sup class="text-blue-600 font-semibold">†</sup>,
            Alex Zhai,
            Clara Huiyi Hu,
            Henryk Michalewski
           Jimin Kim<sup class="text-blue-600 font-semibold">†</sup>,
            Jeonghyun Ahn<sup class="text-blue-600 font-semibold">†</sup>,
            Junhwi Bae<sup class="text-blue-600 font-semibold">†</sup>,
            Xingyou Song,
            Trieu H. Trinh,
            Quoc V. Le,
            Junehyuk Jung<sup class="text-blue-600 font-semibold">◊</sup>
        </p>
    </div>

    <!-- CORRESPONDENCE AND AFFILIATIONS -->
    <div class="text-sm md:text-base text-gray-600 space-y-2 mb-8 p-4 bg-blue-50 rounded-lg border-l-4 border-blue-500">
        <div>
            <sup class="text-blue-600 font-semibold">◊</sup>Corresponding authors: <a href="mailto:thangluong@google.com" class="text-blue-600 hover:text-blue-800 hover:underline">thangluong@google.com</a>, <a href="mailto:junehyuk@google.com" class="text-blue-600 hover:text-blue-800 hover:underline">junehyuk@google.com</a>.
	    <br>
            <sup class="text-blue-600 font-semibold">*</sup>Core and equal contributors
            <sup class="text-blue-600 font-semibold">†</sup> Work previously conducted under Google DeepMind.
        </div>
    </div>

    <!-- NAVIGATION BUTTONS -->
 <div class="grid grid-cols-2 sm:flex sm:flex-wrap gap-4 mb-0">
    <!-- Button 1: Paper -->
    <a href="https://arxiv.org/abs/2511.01846"  target="_blank"
       class="flex items-center justify-center gap-2 px-3 sm:px-4 py-2 text-sm sm:text-base font-medium text-blue-600 bg-white border border-blue-600 rounded-lg shadow-sm hover:bg-blue-50 transition-colors duration-150 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500">
       <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M15.7997 2.21048C15.3897 1.80048 14.6797 2.08048 14.6797 2.65048V6.14048C14.6797 7.60048 15.9197 8.81048 17.4297 8.81048C18.3797 8.82048 19.6997 8.82048 20.8297 8.82048C21.3997 8.82048 21.6997 8.15048 21.2997 7.75048C19.8597 6.30048 17.2797 3.69048 15.7997 2.21048Z" fill="#4b5563"/>
        <path d="M20.5 10.19H17.61C15.24 10.19 13.31 8.26 13.31 5.89V3C13.31 2.45 12.86 2 12.31 2H8.07C4.99 2 2.5 4 2.5 7.57V16.43C2.5 20 4.99 22 8.07 22H15.93C19.01 22 21.5 20 21.5 16.43V11.19C21.5 10.64 21.05 10.19 20.5 10.19ZM11.5 17.75H7.5C7.09 17.75 6.75 17.41 6.75 17C6.75 16.59 7.09 16.25 7.5 16.25H11.5C11.91 16.25 12.25 16.59 12.25 17C12.25 17.41 11.91 17.75 11.5 17.75ZM13.5 13.75H7.5C7.09 13.75 6.75 13.41 6.75 13C6.75 12.59 7.09 12.25 7.5 12.25H13.5C13.91 12.25 14.25 12.59 14.25 13C14.25 13.41 13.91 13.75 13.5 13.75Z" fill="#292D32"/>
        </svg>
        
        <span>Paper</span>
    </a>

   
     <!-- Button 2: Dataset -->
     <a href="https://github.com/google-deepmind/superhuman/tree/main/imobench" target="_blank"
     class="flex items-center justify-center gap-2 px-3 sm:px-4 py-2 text-sm sm:text-base font-medium text-blue-600 bg-white border border-blue-600 rounded-lg shadow-sm hover:bg-blue-50 transition-colors duration-150 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500">
     <svg height="24" aria-hidden="true" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-mark-github v-align-middle">
      <path d="M12 1C5.923 1 1 5.923 1 12c0 4.867 3.149 8.979 7.521 10.436.55.096.756-.233.756-.522 0-.262-.013-1.128-.013-2.049-2.764.509-3.479-.674-3.699-1.292-.124-.317-.66-1.293-1.127-1.554-.385-.207-.936-.715-.014-.729.866-.014 1.485.797 1.691 1.128.99 1.663 2.571 1.196 3.204.907.096-.715.385-1.196.701-1.471-2.448-.275-5.005-1.224-5.005-5.432 0-1.196.426-2.186 1.128-2.956-.111-.275-.496-1.402.11-2.915 0 0 .921-.288 3.024 1.128a10.193 10.193 0 0 1 2.75-.371c.936 0 1.871.123 2.75.371 2.104-1.43 3.025-1.128 3.025-1.128.605 1.513.221 2.64.111 2.915.701.77 1.127 1.747 1.127 2.956 0 4.222-2.571 5.157-5.019 5.432.399.344.743 1.004.743 2.035 0 1.471-.014 2.654-.014 3.025 0 .289.206.632.756.522C19.851 20.979 23 16.854 23 12c0-6.077-4.922-11-11-11Z"></path>
  </svg>
      <span> Dataset</span>
  </a>
   <!-- Button 3: Leaderboards -->
   <a href="#leaderboard" 
   class="flex items-center justify-center gap-2 px-3 sm:px-4 py-2 text-sm sm:text-base font-medium text-blue-600 bg-white border border-blue-600 rounded-lg shadow-sm hover:bg-blue-50 transition-colors duration-150 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500">
   <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
    <path d="M11.25 18.2509H9C7.9 18.2509 7 19.1509 7 20.2509V20.5009H6C5.59 20.5009 5.25 20.8409 5.25 21.2509C5.25 21.6609 5.59 22.0009 6 22.0009H18C18.41 22.0009 18.75 21.6609 18.75 21.2509C18.75 20.8409 18.41 20.5009 18 20.5009H17V20.2509C17 19.1509 16.1 18.2509 15 18.2509H12.75V15.9609C12.5 15.9909 12.25 16.0009 12 16.0009C11.75 16.0009 11.5 15.9909 11.25 15.9609V18.2509Z" fill="#1f2937"/>
    <path d="M18.4793 11.64C19.1393 11.39 19.7193 10.98 20.1793 10.52C21.1093 9.49 21.7193 8.26 21.7193 6.82C21.7193 5.38 20.5893 4.25 19.1493 4.25H18.5893C17.9393 2.92 16.5793 2 14.9993 2H8.9993C7.4193 2 6.0593 2.92 5.4093 4.25H4.8493C3.4093 4.25 2.2793 5.38 2.2793 6.82C2.2793 8.26 2.8893 9.49 3.8193 10.52C4.2793 10.98 4.8593 11.39 5.5193 11.64C6.5593 14.2 9.0593 16 11.9993 16C14.9393 16 17.4393 14.2 18.4793 11.64ZM14.8393 8.45L14.2193 9.21C14.1193 9.32 14.0493 9.54 14.0593 9.69L14.1193 10.67C14.1593 11.27 13.7293 11.58 13.1693 11.36L12.2593 11C12.1193 10.95 11.8793 10.95 11.7393 11L10.8293 11.36C10.2693 11.58 9.8393 11.27 9.8793 10.67L9.9393 9.69C9.9493 9.54 9.8793 9.32 9.7793 9.21L9.1593 8.45C8.7693 7.99 8.9393 7.48 9.5193 7.33L10.4693 7.09C10.6193 7.05 10.7993 6.91 10.8793 6.78L11.4093 5.96C11.7393 5.45 12.2593 5.45 12.5893 5.96L13.1193 6.78C13.1993 6.91 13.3793 7.05 13.5293 7.09L14.4793 7.33C15.0593 7.48 15.2293 7.99 14.8393 8.45Z" fill="#292D32"/>
    </svg>
    
    <span> Leaderboards</span>
</a>
</div>
 
    <!-- Introduction Section -->
    <section class="mb-12">
        <h2 class="text-3xl md:text-4xl font-bold text-gray-900 mb-6 mt-12 pb-3 border-b border-gray-200">
            Introduction
        </h2>
        <div class="prose prose-lg max-w-none text-gray-800 leading-relaxed space-y-4">
            <p>In July 2025, we celebrated a historic <a href="https://deepmind.google/discover/blog/advanced-version-of-gemini-with-deep-think-officially-achieves-gold-medal-standard-at-the-international-mathematical-olympiad/" class="text-blue-600 hover:text-blue-800 hover:underline font-medium">achievement</a>: our advanced Gemini model with Deep Think technology reached a gold-medal standard at the International Mathematical Olympiad (IMO). This was a landmark moment for AI. But the win wasn't just about getting strong performances at IMO problems - it was about building a system capable of deep, robust mathematical reasoning.</p>
            <p>At <a href="https://2025.emnlp.org/" class="text-blue-600 hover:text-blue-800 hover:underline font-medium">EMNLP 2025</a>, we are excited to introduce <a href="https://aclanthology.org/2025.emnlp-main.1794/" class="text-blue-600 hover:text-blue-800 hover:underline font-medium">IMO-Bench</a>, a suite of advanced reasoning benchmarks that played a crucial role in our IMO-gold journey and were designed to push the frontiers of mathematical reasoning in AI. Vetted by a panel of IMO medalists and mathematicians (<em>together, they won 10 gold and 5 silver IMO medals</em>), IMO-Bench specifically targets the level of IMO due to its notoriously difficult problems, which require both rigorous multi-step reasoning and creativity beyond simple application of known formulas. We <a href="https://github.com/google-deepmind/superhuman/tree/main/imobench/" class="text-blue-600 hover:text-blue-800 hover:underline font-medium">release</a> IMO-Bench together with rich grading data to the community to help enable further advancements towards robust mathematical reasoning.</p>

        <blockquote class="border-l-4 border-blue-500 pl-6 py-4 my-6 bg-blue-50 rounded-r-lg text-gray-700">
            <p class="mb-0   text-blue-800 italic text-xl mb-6">&ldquo;IMO-Bench is an impressive collection of high quality data for AI evaluation covering a diverse and representative set of topics and difficulties in high school level math competitions. I am very pleased to see this benchmark being used in developing an AI that achieved gold medal standard this year.&rdquo;</p>
            <p class="mb-0  text-blue-800 text-base">Yufei Zhao (<em>IMO Gold Medalist, 3-time Putnam Fellow, and Professor of Mathematics, MIT</em>).</p>
        </blockquote>
       </div>
      
    </section>

    <!-- IMO-Bench at a glance Section -->
    <section class="mb-12">
        <h2 class="text-3xl md:text-4xl font-bold text-gray-900 mb-6 mt-12 pb-3 border-b border-gray-200">
            IMO-Bench at a glance
        </h2>
        <div class="prose prose-lg max-w-none text-gray-800 leading-relaxed space-y-4">
            <p>IMO-Bench consists of three benchmarks that judge models on diverse capabilities: <em >IMO-AnswerBench</em> - a large-scale test on getting the right answer, <em>IMO-ProofBench</em> - a next-level evaluation for proof writing, and <em>IMO-GradingBench</em> to enable further progress in automatic evaluation of long-form answers.</p>
        </div>

        <div class="my-8 flex justify-center">
            <div class="w-full md:w-[100%] overflow-x-auto">
                <table class="min-w-full divide-y divide-gray-200 overflow-hidden rounded-xl border border-gray-200 shadow">
                    <thead class="bg-gray-50">
                        <tr>
                            <th scope="col" class="px-6 py-3 text-left text-base font-semibold text-gray-600 uppercase tracking-wider">Benchmark</th>
                            <th scope="col" class="px-6 py-3 text-left text-base font-semibold text-gray-600 uppercase tracking-wider">Size</th>
                            <th scope="col" class="px-6 py-3 text-left text-base font-semibold text-gray-600 uppercase tracking-wider">Task</th>
                        </tr>
                    </thead>
                    <tbody class="bg-white divide-y divide-gray-200">
                        <tr class="odd:bg-white even:bg-gray-50">
                            <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">IMO-AnswerBench</td>
                            <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">400</td>
                            <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">Get the right answer</td>
                        </tr>
                        <tr class="odd:bg-white even:bg-gray-50">
                            <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">IMO-ProofBench</td>
                            <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">60</td>
                            <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">Write a rigorous proof</td>
                        </tr>
                        <tr class="odd:bg-white even:bg-gray-50">
                            <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">IMO-GradingBench</td>
                            <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">1,000</td>
                            <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">Grade a proof</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <p>A key highlight of our work is to show that autograders built with Gemini reasoning correlate well with human evaluations on IMO-ProofBench, as illustrated below, for a wide range of foundation models. This was achieved thanks to the accompanying grading schemes in IMO-Bench, which are suitable for both human experts and automated systems. We ultimately hope to steer the community's focus from final answers to the proofs themselves, enabling a more rigorous assessment of AI reasoning processes.</p>
     

 <!-- Main Plot Image -->
 <div class="my-8 flex justify-center">
   
    <div class="bg-white p-4 rounded-xl w-full md:w-[75%]">
        <img src="imgs/Main-Plot.png" 
             alt="Correlation between human and automatic evaluations on IMO-ProofBench" 
             class="max-w-full h-auto rounded-lg">
             <blockquote class="mt-4 text-gray-700 italic">
                <p class="mb-0 text-base">IMO-ProofBench, a key benchmark in IMO-Bench, for measuring proof-writing capabilities. We demonstrated high correlations between human and automatic evaluations on a variety of public models, including our IMO-gold model <a href="https://deepmind.google/discover/blog/advanced-version-of-gemini-with-deep-think-officially-achieves-gold-medal-standard-at-the-international-mathematical-olympiad/" class="text-blue-600 hover:text-blue-800 hover:underline font-medium">(Luong and Lockhart, 2025)</a>.</p>
            </blockquote>
    </div>
 </div>
    </section>

    <!-- IMO-ProofBench Section -->
    <section class="mb-12">
        <h2 class="text-3xl md:text-4xl font-bold text-gray-900 mb-6 mt-12 pb-3 border-b border-gray-200">
            Beyond Short Answers with IMO-ProofBench
        </h2>
        <div class="prose prose-lg max-w-none text-gray-900 leading-relaxed space-y-4">
            <p>While the final answer accuracy offers a valuable metric for measuring mathematical abilities, it is insufficient for a comprehensive assessment of mathematical reasoning. We, hence, introduce <em>IMO-ProofBench</em> as the next-level evaluation designed to evaluate the ability of AI models in constructing rigorous and valid mathematical arguments. With 60 proof-based problems, the benchmark is divided into two subsets: a basic set covering pre-IMO to IMO-Medium difficulty levels, and an advanced set featuring novel, highly challenging problems simulating complete IMO examinations, up to IMO-Hard level. Our goal for the basic set is to assess models in their early stages of development. Sufficiently strong performance on the basic set would justify progression to the advanced set.</p>

            <p>Performances on the basic IMO-ProofBench varies significantly: while Gemini Deep Think (IMO Gold) achieves a high score of <strong class="text-blue-600">89.0%</strong>, most models score below 60%, indicating that there is still considerable room for improvements. The advanced IMO-ProofBench proves to be a more significant challenge that all non-Gemini models score below 25%. Our IMO-gold model achieved a state-of-the art score of <strong class="text-blue-600">65.7%</strong> according to human evaluations. This represents a substantial leap in capability, but its distance from a perfect score indicates that even the strongest models have room for growth in sophisticated mathematical reasoning.</p>
        </div>

        <div class="my-8 flex justify-center">
            <div class="bg-white p-4 rounded-xl ">
                <img src="imgs/model_accuracy_proofbench.png" 
                     alt="Expert evaluation on IMO-ProofBench"
                     class="max-w-full h-auto rounded-lg">
                     <blockquote class="mt-4 text-gray-700 italic">
                        <p class="mb-0">Expert evaluation results on the Basic and Advanced subsets of IMO-ProofBench. Scores are presented as a percentage of the total possible points, with each problem graded from 0-7.</p>
                    </blockquote>
            </div>
        </div>

        <h3 class="text-2xl md:text-3xl font-bold text-gray-900 mb-4 mt-8">
            Proof Autograder
        </h3>

        <div class="prose prose-lg max-w-none text-gray-800 leading-relaxed space-y-4">
            <p>While human expert evaluation remains the gold standard for mathematical proofs, its cost and time intensity limit scalable research. To address this, we built <em>ProofAutoGrader</em>, an automatic grader for IMO-ProofBench. The autograder leverages Gemini 2.5 Pro, providing it with a prompt containing the problem statement, the candidate solution, a reference solution, and specific grading guidelines.</p>

            <p>When applying ProofAutoGrader to the 14 public models on IMO-ProofBench, the average grades from our automatic grader strongly correlate with human grades, yielding high Pearson correlation coefficients of <strong class="text-blue-600">0.96</strong> and <strong class="text-blue-600">0.93</strong> on both basic and advanced problems respectively. In addition, we also tested ProofAutoGrader on 170 internal systems, developed as part of our IMO <a href="https://deepmind.google/discover/blog/advanced-version-of-gemini-with-deep-think-officially-achieves-gold-medal-standard-at-the-international-mathematical-olympiad/" class="text-blue-600 hover:text-blue-800 hover:underline font-medium">effort</a>. On this larger pool, the automatic grader achieved a lower, but still reasonable Pearson correlation coefficient of <strong class="text-blue-600">0.87</strong>.</p>
        </div>

        <div class="my-8 flex justify-center">
            <div class="bg-white p-4 rounded-xl">
                <img src="imgs/proofgrader_scatterplot.png" 
                     alt="Correlation between human expert grades and ProofAutoGrader scores"
                     class="max-w-full h-auto rounded-lg">
                     <blockquote class="mt-4 text-gray-700 italic">
                        <p class="mb-0 text-base">Correlation between ProofAutoGrader and human experts on IMO-Proof Bench, evaluated over 14 public models (<em>left</em>) and 170 internal models during our IMO-gold journey (<em>right</em>).</p>
                    </blockquote>
            </div>
        </div>
       
    </section>
<!-- Other Benchmarks Section -->
<section class="mb-12">
    <h2 class="text-3xl md:text-4xl font-bold text-gray-900 mb-6 mt-12 pb-3 border-b border-gray-200">
        Other Benchmarks in IMO-Bench
    </h2>

    <!-- IMO-AnswerBench Subsection -->
    <h3 class="text-2xl md:text-3xl font-bold text-gray-900 mb-4 mt-8">
        IMO-AnswerBench
    </h3>


    <div class="prose prose-lg max-w-none text-gray-900 leading-relaxed space-y-4">
        <p><em>IMO-AnswerBench</em> is a standard benchmark, consisting of 400 problems with verifiable answers carefully chosen from past Olympiad competitions. The problems span across four IMO categories (Algebra, Combinatorics, Geometry, and Number Theory) and are altered by experts to avoid memorization. For each category, the benchmark contains 100 problems across four levels of difficulty: pre-IMO (middle school or pre-Math Olympiad problems), IMO-Easy (equivalent to Problem 1 or Problem 4 at the IMO), IMO-Medium (equivalent to Problem 2 or Problem 5 at the IMO) and IMO-Hard (equivalent to Problem 3 or Problem 6 at the IMO or post-Math Olympiad problems).</p>

<div class="my-8 mb-4 flex justify-center">
    <div class="w-full md:w-[100%] overflow-x-auto">
        <table class="min-w-full divide-y divide-gray-200 overflow-hidden rounded-xl border border-gray-200 shadow">
            <thead class="bg-gray-50">
                <tr>
                    <th scope="col" class="px-6 py-3 text-left text-base font-semibold text-gray-600 uppercase tracking-wider">Category</th>
                    <th scope="col" class="px-6 py-3 text-left text-base font-semibold text-gray-600 uppercase tracking-wider">Pre-IMO</th>
                    <th scope="col" class="px-6 py-3 text-left text-base font-semibold text-gray-600 uppercase tracking-wider">IMO-Easy</th>
                    <th scope="col" class="px-6 py-3 text-left text-base font-semibold text-gray-600 uppercase tracking-wider">IMO-Medium</th>
                    <th scope="col" class="px-6 py-3 text-left text-base font-semibold text-gray-600 uppercase tracking-wider">IMO-Hard</th>
                </tr>
            </thead>
            <tbody class="bg-white divide-y divide-gray-200">
                <tr class="odd:bg-white even:bg-gray-50">
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">Algebra</td>
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">11</td>
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">46</td>
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">32</td>
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">11</td>
                </tr>
                <tr class="odd:bg-white even:bg-gray-50">
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">Combinatorics</td>
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">4</td>
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">19</td>
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">31</td>
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">46</td>
                </tr>
                <tr class="odd:bg-white even:bg-gray-50">
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">Geometry</td>
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">13</td>
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">44</td>
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">32</td>
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">11</td>
                </tr>
                <tr class="odd:bg-white even:bg-gray-50">
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">Number Theory</td>
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">2</td>
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">20</td>
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">31</td>
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">47</td>
                </tr>
            </tbody>
        </table>
        <blockquote class="my-6 italic text-center">
            <p class="mb-0 text-gray-600">Difficulty statistics for IMO-AnsBench.</p>
        </blockquote>
    </div>
   
</div>
    <p>Problems were chosen from a variety of topics whose solutions require different problem solving techniques to ensure a diverse representation of topics, ideas, and domain knowledge as illustrated below.</p>
    </div>

    <div class="my-8 flex justify-center">
        <div class="bg-white p-4 rounded-xl ">
            <img src="imgs/imo_answer_bench.png" 
                 alt="IMO-AnswerBench Topic Distribution" 
                 class="max-w-full h-auto rounded-lg">
                 <blockquote class="mt-4 italic">
                    <p class="mb-0 text-gray-600">Topic distribution by category in IMO-AnswerBench. Number Theory and Combinatorics have the most topics which reflect the broad knowledge required to solve these problems while Geometry is mostly skewed towards angle and sidelength computation problems due to the nature of the short answer benchmark.</p>
                </blockquote>
        </div>
    </div>
    <!-- IMO-GradingBench Subsection -->
    <h3 class="text-2xl md:text-3xl font-bold text-gray-900 mb-4 mt-8">
        IMO-GradingBench
    </h3>
    <div class="prose prose-lg max-w-none text-gray-800 leading-relaxed space-y-4">
    <p>While IMO-ProofBench evaluates proof-writing abilities, it is equally important to assess models in terms of their ability to evaluate the correctness of given solutions. This capability is crucial for developing reliable automated grading systems and improving general mathematical reasoning. As part of our IMO effort, we have benchmarked extensively many internal models on the advanced set of IMO-Proof Bench using human evaluations. These human gradings led to the creation of <em>IMO-GradingBench</em> with 1000 examples, each containing a problem statement, a proposed solution, and its human-assigned grade (on a 0–7 scale). To reduce noise from fine-grained scoring, we frame the evaluation as a four-way classification by mapping the given IMO points to the labels (Correct, Almost, Partial, Incorrect) as detailed below.</p>
    </div>

<div class="my-8 mb-4 flex justify-center">
    <div class="w-full md:w-[100%] overflow-x-auto">
        <table class="min-w-full divide-y divide-gray-200 overflow-hidden rounded-xl border border-gray-200 shadow">
            <thead class="bg-gray-50">
                <tr>
                    <th scope="col" class="px-6 py-3 text-left text-base font-semibold text-gray-600 uppercase tracking-wider">Category</th>
                    <th scope="col" class="px-6 py-3 text-left text-base font-semibold text-gray-600 uppercase tracking-wider">IMO Points</th>
                    <th scope="col" class="px-6 py-3 text-left text-base font-semibold text-gray-600 uppercase tracking-wider">Solution quality</th>
                </tr>
            </thead>
            <tbody class="bg-white divide-y divide-gray-200">
                <tr class="odd:bg-white even:bg-gray-50">
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">Correct</td>
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">7</td>
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">Fully correct, rigorous, and complete</td>
                </tr>
                <tr class="odd:bg-white even:bg-gray-50">
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">Almost</td>
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">6</td>
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">Almost correct, minor errors</td>
                </tr>
                <tr class="odd:bg-white even:bg-gray-50">
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">Partial</td>
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">1</td>
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">Mostly incorrect, some relevant results</td>
                </tr>
                <tr class="odd:bg-white even:bg-gray-50">
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">Incorrect</td>
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">0</td>
                    <td class="px-6 py-4 whitespace-nowrap text-base text-gray-900">Completely incorrect or irrelevant.</td>
                </tr>
            </tbody>
        </table>
        <blockquote class="my-6 italic text-center">
            <p class="mb-0 text-gray-600">Our simplified IMO ratings.</p>
        </blockquote>
    </div>
</div>
<p>To ensure a robust evaluation, the dataset has been balanced with a roughly equal number of examples per category.When problems are grouped by their IMO difficulties, a clear trend emerges. The proportion of correct and almost solutions decreases as the intended difficulty moves from IMO-easy to IMO-hard, while the proportion of incorrect and partial solutions increases. This confirms that the grading distribution of IMO-GradingBench aligns with its assigned difficulty levels.</p>
    <div class="my-8 flex justify-center">
        <div class="bg-white p-4 rounded-xl  md:w-[75%]">
            <img src="imgs/imo_grading_bench.png" 
                 alt="Distribution of human grades in IMO-GradingBench" 
                 class="max-w-full h-auto rounded-lg">
                 <blockquote class="mt-4 italic">
                    <p class="mb-0 text-gray-600">Grade distribution for solutions in IMO-GradingBench by difficulty levels (IMO-Hard, IMO-Medium, IMO-Easy).</p>
                </blockquote>
        </div>
    </div>
</section>

<!-- Leaderboard Section -->
<section class="mb-12" id="leaderboard">
    <h2 class="text-3xl md:text-4xl font-bold text-gray-900 mb-6 mt-12 pb-3 border-b border-gray-200">
        Leaderboards
    </h2>
    <div class="prose prose-lg max-w-none text-gray-900 leading-relaxed space-y-4">
        <p>Our Gemini Deep Think (IMO Gold) model achieved an overall accuracy of <strong class="text-blue-600">80.0%</strong>, surpassing the best non-Gemini model (Grok 4) by 6.9% and the best open-weight model (DeepSeek R1) by 19.2%. Latest models such as GPT-5 are still struggling with overall accuracy of only 65.6% respectively. We show breakdowns of performances across the four categories (Algebra, Combinatorics, Geometry, Number Theory) in the figure below. Generally, models perform the worst in Combinatorics, potentially highlighting difficulties with advanced abstract reasoning.</p>
    </div>

    <div class="my-8 flex justify-center">
        <div class="bg-white p-4 rounded-xl ">
            <img src="imgs/model_accuracy_answerbench.png" 
                 alt="Model Accuracy on IMO-AnswerBench"
                 class="max-w-full h-auto rounded-lg">
                 <blockquote class="border-blue-500 mt-4 rounded-r-lg  italic">
                    <p class="mb-0 text-gray-600">Model accuracy on IMO-AnswerBench. Results are averaged over 8 runs, except for Gemini 2.5 Deep Think and Gemini Deep Think (IMO Gold) (single run).</p>
                </blockquote>
        </div>
    </div>
</section>

<!-- Citing Section -->
<section>
    <h2 class="text-3xl md:text-4xl font-bold text-gray-900 mb-6 mt-12 pb-3 border-b border-gray-200">
        Citing this work
    </h2>
     <div class="bg-blue-50 rounded-xl p-6 overflow-x-auto border border-blue-500">
        <pre class="text-gray-900 font-mono text-sm md:text-base leading-relaxed whitespace-pre-wrap"><code>@inproceedings{luong-etal-2025-towards,
title = "Towards Robust Mathematical Reasoning",
author  = {Thang Luong and Dawsen Hwang and Hoang H. Nguyen and Golnaz Ghiasi and Yuri Chervonyi and Insuk Seo and Junsu Kim and Garrett Bingham and Jonathan Lee and Swaroop Mishra and Alex Zhai and Clara Huiyi Hu and Henryk Michalewski and Jimin Kim and Jeonghyun Ahn and Junhwi Bae and Xingyou Song and Trieu H. Trinh and Quoc V. Le and Junehyuk Jung},
booktitle = "Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing",
year = "2025",
url = "https://aclanthology.org/2025.emnlp-main.1794/",
}
</code></pre>
    </div>
</section>

</div>
</body>
